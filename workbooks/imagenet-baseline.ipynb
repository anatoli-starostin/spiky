{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# ImageNet Baseline - Simple ResNet\n",
        "\n",
        "This notebook implements a simple baseline on ImageNet using a ResNet architecture.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Global preparations\n",
        "import sys\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader\n",
        "from tqdm.notebook import tqdm\n",
        "import numpy as np\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "random_seed = 1\n",
        "torch.manual_seed(random_seed)\n",
        "np.random.seed(random_seed)\n",
        "torch.backends.cudnn.enabled = True\n",
        "print(f\"PyTorch version: {torch.__version__}\")\n",
        "print(f\"Device: {device}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Data Loading\n",
        "\n",
        "ImageNet dataset loading with standard augmentations for training and validation.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ImageNet data paths (adjust these to your ImageNet location)\n",
        "imagenet_train_path = '/path/to/imagenet/train'  # Update this path\n",
        "imagenet_val_path = '/path/to/imagenet/val'      # Update this path\n",
        "\n",
        "# Standard ImageNet normalization\n",
        "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                                 std=[0.229, 0.224, 0.225])\n",
        "\n",
        "# Training transforms with augmentation\n",
        "train_transform = transforms.Compose([\n",
        "    transforms.RandomResizedCrop(224),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ColorJitter(brightness=0.4, contrast=0.4, saturation=0.4, hue=0.1),\n",
        "    transforms.ToTensor(),\n",
        "    normalize,\n",
        "])\n",
        "\n",
        "# Validation transforms (no augmentation)\n",
        "val_transform = transforms.Compose([\n",
        "    transforms.Resize(256),\n",
        "    transforms.CenterCrop(224),\n",
        "    transforms.ToTensor(),\n",
        "    normalize,\n",
        "])\n",
        "\n",
        "# Note: You need to have ImageNet dataset downloaded\n",
        "# For demonstration, we'll use ImageNet-like dataset or CIFAR-100 as a proxy\n",
        "# Uncomment and update paths when you have ImageNet available\n",
        "\"\"\"\n",
        "train_dataset = torchvision.datasets.ImageFolder(\n",
        "    root=imagenet_train_path,\n",
        "    transform=train_transform\n",
        ")\n",
        "\n",
        "val_dataset = torchvision.datasets.ImageFolder(\n",
        "    root=imagenet_val_path,\n",
        "    transform=val_transform\n",
        ")\n",
        "\"\"\"\n",
        "\n",
        "# Using CIFAR-100 as a smaller proxy for testing (same structure as ImageNet)\n",
        "# Replace with ImageNet when available\n",
        "print(\"Using CIFAR-100 as a proxy dataset. Replace with ImageNet for full experiments.\")\n",
        "\n",
        "train_transform_cifar = transforms.Compose([\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomCrop(32, padding=4),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5071, 0.4867, 0.4408), (0.2675, 0.2565, 0.2761)),\n",
        "])\n",
        "\n",
        "val_transform_cifar = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5071, 0.4867, 0.4408), (0.2675, 0.2565, 0.2761)),\n",
        "])\n",
        "\n",
        "train_dataset = torchvision.datasets.CIFAR100(\n",
        "    root='./data',\n",
        "    train=True,\n",
        "    download=True,\n",
        "    transform=train_transform_cifar\n",
        ")\n",
        "\n",
        "val_dataset = torchvision.datasets.CIFAR100(\n",
        "    root='./data',\n",
        "    train=False,\n",
        "    download=True,\n",
        "    transform=val_transform_cifar\n",
        ")\n",
        "\n",
        "batch_size = 128\n",
        "num_workers = 4\n",
        "\n",
        "train_loader = DataLoader(\n",
        "    train_dataset,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=True,\n",
        "    num_workers=num_workers,\n",
        "    pin_memory=True\n",
        ")\n",
        "\n",
        "val_loader = DataLoader(\n",
        "    val_dataset,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=False,\n",
        "    num_workers=num_workers,\n",
        "    pin_memory=True\n",
        ")\n",
        "\n",
        "print(f\"Train dataset size: {len(train_dataset)}\")\n",
        "print(f\"Val dataset size: {len(val_dataset)}\")\n",
        "print(f\"Number of classes: {len(train_dataset.classes)}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Baseline Model\n",
        "\n",
        "We'll use ResNet18 as a simple baseline. This can be easily replaced with ResNet50 or other architectures.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load pre-trained ResNet18 and modify for our dataset\n",
        "# For CIFAR-100, we'll modify the first conv layer to handle 32x32 images\n",
        "# For ImageNet (224x224), use standard ResNet18\n",
        "\n",
        "num_classes = len(train_dataset.classes)\n",
        "\n",
        "if hasattr(train_dataset, 'classes'):\n",
        "    # CIFAR-100 or similar small dataset\n",
        "    model = torchvision.models.resnet18(weights=None)  # Start from scratch\n",
        "    # Modify first conv layer for smaller input\n",
        "    model.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "    model.maxpool = nn.Identity()  # Remove maxpool for smaller images\n",
        "    model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
        "else:\n",
        "    # ImageNet\n",
        "    model = torchvision.models.resnet18(weights=None)\n",
        "    model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
        "\n",
        "model = model.to(device)\n",
        "\n",
        "# Count parameters\n",
        "total_params = sum(p.numel() for p in model.parameters())\n",
        "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "print(f\"Model: ResNet18\")\n",
        "print(f\"Total parameters: {total_params:,}\")\n",
        "print(f\"Trainable parameters: {trainable_params:,}\")\n",
        "print(f\"Number of classes: {num_classes}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Training Setup\n",
        "\n",
        "Define loss function, optimizer, and learning rate scheduler.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(\n",
        "    model.parameters(),\n",
        "    lr=0.1,\n",
        "    momentum=0.9,\n",
        "    weight_decay=1e-4\n",
        ")\n",
        "\n",
        "# Learning rate scheduler\n",
        "scheduler = torch.optim.lr_scheduler.StepLR(\n",
        "    optimizer,\n",
        "    step_size=30,\n",
        "    gamma=0.1\n",
        ")\n",
        "\n",
        "print(\"Optimizer: SGD with momentum 0.9, weight decay 1e-4\")\n",
        "print(\"Initial learning rate: 0.1\")\n",
        "print(\"Scheduler: StepLR (reduce by 0.1 every 30 epochs)\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Training and Evaluation Functions\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def train_one_epoch(model, train_loader, criterion, optimizer, device):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    \n",
        "    pbar = tqdm(train_loader, leave=False)\n",
        "    for inputs, targets in pbar:\n",
        "        inputs, targets = inputs.to(device), targets.to(device)\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, targets)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        running_loss += loss.item()\n",
        "        _, predicted = outputs.max(1)\n",
        "        total += targets.size(0)\n",
        "        correct += predicted.eq(targets).sum().item()\n",
        "        \n",
        "        pbar.set_description(f'Loss: {loss.item():.4f}, Acc: {100.*correct/total:.2f}%')\n",
        "    \n",
        "    epoch_loss = running_loss / len(train_loader)\n",
        "    epoch_acc = 100. * correct / total\n",
        "    return epoch_loss, epoch_acc\n",
        "\n",
        "\n",
        "def evaluate(model, val_loader, criterion, device):\n",
        "    model.eval()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        pbar = tqdm(val_loader, leave=False)\n",
        "        for inputs, targets in pbar:\n",
        "            inputs, targets = inputs.to(device), targets.to(device)\n",
        "            \n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, targets)\n",
        "            \n",
        "            running_loss += loss.item()\n",
        "            _, predicted = outputs.max(1)\n",
        "            total += targets.size(0)\n",
        "            correct += predicted.eq(targets).sum().item()\n",
        "            \n",
        "            pbar.set_description(f'Loss: {loss.item():.4f}, Acc: {100.*correct/total:.2f}%')\n",
        "    \n",
        "    epoch_loss = running_loss / len(val_loader)\n",
        "    epoch_acc = 100. * correct / total\n",
        "    return epoch_loss, epoch_acc\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Training Loop\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "num_epochs = 100  # Adjust as needed\n",
        "train_losses = []\n",
        "train_accs = []\n",
        "val_losses = []\n",
        "val_accs = []\n",
        "\n",
        "print(f\"Starting training for {num_epochs} epochs...\")\n",
        "print(f\"Batch size: {batch_size}\")\n",
        "print(f\"Device: {device}\\n\")\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    print(f'Epoch {epoch+1}/{num_epochs}')\n",
        "    print(f'Learning rate: {scheduler.get_last_lr()[0]:.6f}')\n",
        "    \n",
        "    # Train\n",
        "    train_loss, train_acc = train_one_epoch(model, train_loader, criterion, optimizer, device)\n",
        "    train_losses.append(train_loss)\n",
        "    train_accs.append(train_acc)\n",
        "    \n",
        "    # Validate\n",
        "    val_loss, val_acc = evaluate(model, val_loader, criterion, device)\n",
        "    val_losses.append(val_loss)\n",
        "    val_accs.append(val_acc)\n",
        "    \n",
        "    # Update learning rate\n",
        "    scheduler.step()\n",
        "    \n",
        "    print(f'Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.2f}%')\n",
        "    print(f'Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.2f}%')\n",
        "    print('-' * 60)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Plot Results\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Plot training curves\n",
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))\n",
        "\n",
        "# Loss plot\n",
        "ax1.plot(train_losses, label='Train Loss', color='blue')\n",
        "ax1.plot(val_losses, label='Val Loss', color='red')\n",
        "ax1.set_xlabel('Epoch')\n",
        "ax1.set_ylabel('Loss')\n",
        "ax1.set_title('Training and Validation Loss')\n",
        "ax1.legend()\n",
        "ax1.grid(True)\n",
        "\n",
        "# Accuracy plot\n",
        "ax2.plot(train_accs, label='Train Acc', color='blue')\n",
        "ax2.plot(val_accs, label='Val Acc', color='red')\n",
        "ax2.set_xlabel('Epoch')\n",
        "ax2.set_ylabel('Accuracy (%)')\n",
        "ax2.set_title('Training and Validation Accuracy')\n",
        "ax2.legend()\n",
        "ax2.grid(True)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(f\"Best validation accuracy: {max(val_accs):.2f}% at epoch {val_accs.index(max(val_accs))+1}\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
