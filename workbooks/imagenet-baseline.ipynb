{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ImageNet Baseline - Simple ResNet\n",
    "\n",
    "This notebook implements a simple baseline on ImageNet using a ResNet architecture.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.1.2+cu121\n",
      "Device: cuda:5\n"
     ]
    }
   ],
   "source": [
    "# Global preparations\n",
    "import sys\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm.notebook import tqdm\n",
    "import numpy as np\n",
    "\n",
    "sys.path.insert(0, os.path.expanduser('~/spiky'))\n",
    "device = 'cuda:5'\n",
    "random_seed = 1\n",
    "torch.manual_seed(random_seed)\n",
    "np.random.seed(random_seed)\n",
    "torch.backends.cudnn.enabled = True\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"Device: {device}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading\n",
    "\n",
    "ImageNet dataset loading with standard augmentations for training and validation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using CIFAR-100 as a proxy dataset. Replace with ImageNet for full experiments.\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Train dataset size: 50000\n",
      "Val dataset size: 10000\n",
      "Number of classes: 100\n"
     ]
    }
   ],
   "source": [
    "# ImageNet data paths (adjust these to your ImageNet location)\n",
    "imagenet_train_path = '/path/to/imagenet/train'  # Update this path\n",
    "imagenet_val_path = '/path/to/imagenet/val'      # Update this path\n",
    "\n",
    "# Standard ImageNet normalization\n",
    "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                 std=[0.229, 0.224, 0.225])\n",
    "\n",
    "# Training transforms with augmentation\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(224),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ColorJitter(brightness=0.4, contrast=0.4, saturation=0.4, hue=0.1),\n",
    "    transforms.ToTensor(),\n",
    "    normalize,\n",
    "])\n",
    "\n",
    "# Validation transforms (no augmentation)\n",
    "val_transform = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    normalize,\n",
    "])\n",
    "\n",
    "# Note: You need to have ImageNet dataset downloaded\n",
    "# For demonstration, we'll use ImageNet-like dataset or CIFAR-100 as a proxy\n",
    "# Uncomment and update paths when you have ImageNet available\n",
    "\"\"\"\n",
    "train_dataset = torchvision.datasets.ImageFolder(\n",
    "    root=imagenet_train_path,\n",
    "    transform=train_transform\n",
    ")\n",
    "\n",
    "val_dataset = torchvision.datasets.ImageFolder(\n",
    "    root=imagenet_val_path,\n",
    "    transform=val_transform\n",
    ")\n",
    "\"\"\"\n",
    "\n",
    "# Using CIFAR-100 as a smaller proxy for testing (same structure as ImageNet)\n",
    "# Replace with ImageNet when available\n",
    "print(\"Using CIFAR-100 as a proxy dataset. Replace with ImageNet for full experiments.\")\n",
    "\n",
    "train_transform_cifar = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5071, 0.4867, 0.4408), (0.2675, 0.2565, 0.2761)),\n",
    "])\n",
    "\n",
    "val_transform_cifar = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5071, 0.4867, 0.4408), (0.2675, 0.2565, 0.2761)),\n",
    "])\n",
    "\n",
    "train_dataset = torchvision.datasets.CIFAR100(\n",
    "    root='./data',\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=train_transform_cifar\n",
    ")\n",
    "\n",
    "val_dataset = torchvision.datasets.CIFAR100(\n",
    "    root='./data',\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=val_transform_cifar\n",
    ")\n",
    "\n",
    "batch_size = 512\n",
    "num_workers = 4\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=num_workers,\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    num_workers=num_workers,\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "print(f\"Train dataset size: {len(train_dataset)}\")\n",
    "print(f\"Val dataset size: {len(val_dataset)}\")\n",
    "print(f\"Number of classes: {len(train_dataset.classes)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline Model\n",
    "\n",
    "We'll use ResNet18 as a simple baseline. This can be easily replaced with ResNet50 or other architectures.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: ResNet18\n",
      "Total parameters: 11,220,132\n",
      "Trainable parameters: 11,220,132\n",
      "Number of classes: 100\n"
     ]
    }
   ],
   "source": [
    "# Load pre-trained ResNet18 and modify for our dataset\n",
    "# For CIFAR-100, we'll modify the first conv layer to handle 32x32 images\n",
    "# For ImageNet (224x224), use standard ResNet18\n",
    "\n",
    "num_classes = len(train_dataset.classes)\n",
    "\n",
    "if hasattr(train_dataset, 'classes'):\n",
    "    # CIFAR-100 or similar small dataset\n",
    "    model = torchvision.models.resnet18(weights=None)  # Start from scratch\n",
    "    # Modify first conv layer for smaller input\n",
    "    model.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "    model.maxpool = nn.Identity()  # Remove maxpool for smaller images\n",
    "    model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
    "else:\n",
    "    # ImageNet\n",
    "    model = torchvision.models.resnet18(weights=None)\n",
    "    model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
    "\n",
    "model = model.to(device)\n",
    "\n",
    "# Count parameters\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f\"Model: ResNet18\")\n",
    "print(f\"Total parameters: {total_params:,}\")\n",
    "print(f\"Trainable parameters: {trainable_params:,}\")\n",
    "print(f\"Number of classes: {num_classes}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Setup\n",
    "\n",
    "Define loss function, optimizer, and learning rate scheduler.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimizer: SGD with momentum 0.9, weight decay 1e-4\n",
      "Initial learning rate: 0.1\n",
      "Scheduler: StepLR (reduce by 0.1 every 30 epochs)\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(\n",
    "    model.parameters(),\n",
    "    lr=0.1,\n",
    "    momentum=0.9,\n",
    "    weight_decay=1e-4\n",
    ")\n",
    "\n",
    "# Learning rate scheduler\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(\n",
    "    optimizer,\n",
    "    step_size=30,\n",
    "    gamma=0.1\n",
    ")\n",
    "\n",
    "print(\"Optimizer: SGD with momentum 0.9, weight decay 1e-4\")\n",
    "print(\"Initial learning rate: 0.1\")\n",
    "print(\"Scheduler: StepLR (reduce by 0.1 every 30 epochs)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and Evaluation Functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(model, train_loader, criterion, optimizer, device):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    pbar = tqdm(train_loader, leave=False)\n",
    "    for inputs, targets in pbar:\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += targets.size(0)\n",
    "        correct += predicted.eq(targets).sum().item()\n",
    "        \n",
    "        pbar.set_description(f'Loss: {loss.item():.4f}, Acc: {100.*correct/total:.2f}%')\n",
    "    \n",
    "    epoch_loss = running_loss / len(train_loader)\n",
    "    epoch_acc = 100. * correct / total\n",
    "    return epoch_loss, epoch_acc\n",
    "\n",
    "\n",
    "def evaluate(model, val_loader, criterion, device):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        pbar = tqdm(val_loader, leave=False)\n",
    "        for inputs, targets in pbar:\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            \n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += targets.size(0)\n",
    "            correct += predicted.eq(targets).sum().item()\n",
    "            \n",
    "            pbar.set_description(f'Loss: {loss.item():.4f}, Acc: {100.*correct/total:.2f}%')\n",
    "    \n",
    "    epoch_loss = running_loss / len(val_loader)\n",
    "    epoch_acc = 100. * correct / total\n",
    "    return epoch_loss, epoch_acc\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Loop\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 100  # Adjust as needed\n",
    "train_losses = []\n",
    "train_accs = []\n",
    "val_losses = []\n",
    "val_accs = []\n",
    "\n",
    "print(f\"Starting training for {num_epochs} epochs...\")\n",
    "print(f\"Batch size: {batch_size}\")\n",
    "print(f\"Device: {device}\\n\")\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    print(f'Epoch {epoch+1}/{num_epochs}')\n",
    "    print(f'Learning rate: {scheduler.get_last_lr()[0]:.6f}')\n",
    "    \n",
    "    # Train\n",
    "    train_loss, train_acc = train_one_epoch(model, train_loader, criterion, optimizer, device)\n",
    "    train_losses.append(train_loss)\n",
    "    train_accs.append(train_acc)\n",
    "    \n",
    "    # Validate\n",
    "    val_loss, val_acc = evaluate(model, val_loader, criterion, device)\n",
    "    val_losses.append(val_loss)\n",
    "    val_accs.append(val_acc)\n",
    "    \n",
    "    # Update learning rate\n",
    "    scheduler.step()\n",
    "    \n",
    "    print(f'Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.2f}%')\n",
    "    print(f'Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.2f}%')\n",
    "    print('-' * 60)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot Results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training curves\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "# Loss plot\n",
    "ax1.plot(train_losses, label='Train Loss', color='blue')\n",
    "ax1.plot(val_losses, label='Val Loss', color='red')\n",
    "ax1.set_xlabel('Epoch')\n",
    "ax1.set_ylabel('Loss')\n",
    "ax1.set_title('Training and Validation Loss')\n",
    "ax1.legend()\n",
    "ax1.grid(True)\n",
    "\n",
    "# Accuracy plot\n",
    "ax2.plot(train_accs, label='Train Acc', color='blue')\n",
    "ax2.plot(val_accs, label='Val Acc', color='red')\n",
    "ax2.set_xlabel('Epoch')\n",
    "ax2.set_ylabel('Accuracy (%)')\n",
    "ax2.set_title('Training and Validation Accuracy')\n",
    "ax2.legend()\n",
    "ax2.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Best validation accuracy: {max(val_accs):.2f}% at epoch {val_accs.index(max(val_accs))+1}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LUTNet Adaptation to CIFAR-100\n",
    "\n",
    "Adapting the LUTNet architecture from MNIST to CIFAR-100 classification.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LUTNet components initialized\n"
     ]
    }
   ],
   "source": [
    "# Import LUTNet components\n",
    "import sys\n",
    "import os\n",
    "sys.path.insert(0, os.path.expanduser('~/spiky'))\n",
    "\n",
    "from spiky.lut.LUTLayer import (\n",
    "    Conv2DLUTLayer, LUTSharedContext, SynapseMeta, GradientPolicy, GradientType\n",
    ")\n",
    "from spiky.util.torch_utils import make_lr_getter\n",
    "\n",
    "# Setup LUTNet shared context and metadata\n",
    "summation_dtype = torch.float32\n",
    "\n",
    "synapse_meta = SynapseMeta(\n",
    "    min_weight=-1.0,\n",
    "    max_weight=1.0,\n",
    "    initial_weight=0.0,\n",
    "    initial_noise_level=0.0\n",
    ")\n",
    "\n",
    "shared_lut_ctx = LUTSharedContext()\n",
    "shared_lut_ctx.to_device(device)\n",
    "g_policy = GradientPolicy(GradientType.Dense, normalized=False)\n",
    "\n",
    "print(\"LUTNet components initialized\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LUTNet adapted for CIFAR-100 using Conv2DLUTLayer (standard convolutional, no skip connections)\n",
    "class LutNetCIFAR100(nn.Module):\n",
    "    def __init__(self, device, num_classes=100):\n",
    "        super().__init__()\n",
    "        # CIFAR-100: 32x32 RGB images (3 channels)\n",
    "        self.filter_lut_1 = Conv2DLUTLayer(\n",
    "            input_shape=(32, 32 * 3),  # (32, 96) - concatenate 3 channels along width\n",
    "            n_anchors_per_detector=8,\n",
    "            detectors_shape=(6, 6),\n",
    "            output_kernel_shape=(6, 6),\n",
    "            receptive_field_shape=(5, 5 * 3),\n",
    "            receptive_field_stride_shape=(2, 2 * 3),\n",
    "            lut_receptive_field_shape=(6, 6),\n",
    "            lut_receptive_field_stride_shape=(6, 6),\n",
    "            weights_gradient_policy=g_policy,\n",
    "            shared_context=shared_lut_ctx,\n",
    "            synapse_meta=synapse_meta,\n",
    "            summation_dtype=summation_dtype,\n",
    "            random_seed=random_seed,\n",
    "            _forward_group_size=32,\n",
    "            _backward_group_size=32,\n",
    "            _max_groups_in_growth_buffer=10**7,\n",
    "            device=device\n",
    "        )\n",
    "        \n",
    "        self.filter_lut_2 = Conv2DLUTLayer(\n",
    "            input_shape=(84, 84),\n",
    "            n_anchors_per_detector=8,\n",
    "            detectors_shape=(6, 6),\n",
    "            output_kernel_shape=(6, 6),\n",
    "            receptive_field_shape=(5 * 6, 5 * 6),\n",
    "            receptive_field_stride_shape=(2 * 6, 2 * 6),\n",
    "            lut_receptive_field_shape=(6, 6),\n",
    "            lut_receptive_field_stride_shape=(6, 6),\n",
    "            weights_gradient_policy=g_policy,\n",
    "            shared_context=shared_lut_ctx,\n",
    "            synapse_meta=synapse_meta,\n",
    "            summation_dtype=summation_dtype,\n",
    "            random_seed=random_seed,\n",
    "            _forward_group_size=32,\n",
    "            _backward_group_size=32,\n",
    "            _max_groups_in_growth_buffer=10**7,\n",
    "            device=device\n",
    "        )\n",
    "        \n",
    "        self.filter_lut_3 = Conv2DLUTLayer(\n",
    "            input_shape=(30, 30),\n",
    "            n_anchors_per_detector=8,\n",
    "            detectors_shape=(6, 6),\n",
    "            output_kernel_shape=(6, 6),\n",
    "            receptive_field_shape=(5 * 6, 5 * 6),\n",
    "            receptive_field_stride_shape=(2 * 6, 2 * 6),\n",
    "            lut_receptive_field_shape=(6, 6),\n",
    "            lut_receptive_field_stride_shape=(6, 6),\n",
    "            weights_gradient_policy=g_policy,\n",
    "            shared_context=shared_lut_ctx,\n",
    "            synapse_meta=synapse_meta,\n",
    "            summation_dtype=summation_dtype,\n",
    "            random_seed=random_seed,\n",
    "            _forward_group_size=32,\n",
    "            _backward_group_size=32,\n",
    "            _max_groups_in_growth_buffer=10**7,\n",
    "            device=device\n",
    "        )\n",
    "        \n",
    "        l = []\n",
    "        for i in range(6):\n",
    "            l.append(\n",
    "                LUTLayer(\n",
    "                    n_inputs=36,\n",
    "                    n_anchors_per_detector=10,\n",
    "                    n_detectors=32,\n",
    "                    n_outputs=36,\n",
    "                    synapse_meta=synapse_meta,\n",
    "                    weights_gradient_policy=g_policy,\n",
    "                    shared_context=shared_lut_ctx,\n",
    "                    summation_dtype=summation_dtype,\n",
    "                    random_seed=random_seed,\n",
    "                    device=device\n",
    "                )\n",
    "            )\n",
    "        self.c_luts = nn.ModuleList(l)\n",
    "        self.final_lut = LUTLayer(\n",
    "            n_inputs=36,\n",
    "            n_anchors_per_detector=10,\n",
    "            n_detectors=32,\n",
    "            n_outputs=num_classes,\n",
    "            synapse_meta=synapse_meta,\n",
    "            weights_gradient_policy=g_policy,\n",
    "            shared_context=shared_lut_ctx,\n",
    "            summation_dtype=summation_dtype,\n",
    "            random_seed=random_seed,\n",
    "            device=device\n",
    "        )\n",
    "\n",
    "        # self.final_linear = nn.Linear(900, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        B = x.shape[0]\n",
    "        # CIFAR-100 input: (B, 3, 32, 32)\n",
    "        # Reshape to (B, 1, 32, 96) by concatenating channels along width dimension\n",
    "        if x.shape[1] == 3:\n",
    "            # Reshape: (B, 3, 32, 32) -> (B, 32, 96) -> (B, 1, 32, 96)\n",
    "            x = x.permute(0, 2, 1, 3).contiguous()  # (B, 3, 32, 32) -> (B, 32, 3, 32)\n",
    "            x = x.view(B, 32, 32 * 3)  # (B, 32, 96)\n",
    "            x = x.unsqueeze(1)  # (B, 1, 32, 96)\n",
    "        else:\n",
    "            # Already in correct format\n",
    "            if len(x.shape) == 3:\n",
    "                x = x.unsqueeze(1)\n",
    "        \n",
    "        # First convolutional LUT layer\n",
    "        x = self.filter_lut_1(x)\n",
    "        x = self.filter_lut_2(x)\n",
    "        x = self.filter_lut_3(x).reshape(B, 1, 36)\n",
    "        \n",
    "#        return self.final_linear(x)\n",
    "        \n",
    "        # Intermediate convolutional LUT layers (no skip connections)\n",
    "        for c_lut in self.c_luts:\n",
    "            x = x + c_lut(x)  # No skip connection\n",
    "        \n",
    "        # Final output layer\n",
    "        x = self.final_lut(x)\n",
    "        \n",
    "        # Reshape to (B, num_classes)\n",
    "        return x.reshape(B, -1)\n",
    "    \n",
    "    def setup_external_learning_rate_hook(self, optimizer):\n",
    "        lr_getter = make_lr_getter(optimizer)\n",
    "        self.filter_lut_1.set_external_learning_rate_hook(lr_getter)\n",
    "        self.filter_lut_2.set_external_learning_rate_hook(lr_getter)\n",
    "        for c_lut in self.c_luts:\n",
    "            c_lut.set_external_learning_rate_hook(lr_getter)\n",
    "        self.final_lut.set_external_learning_rate_hook(lr_getter)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LUTNet Model: LutNetCIFAR100(\n",
      "  (filter_lut_1): Conv2DLUTLayer(input_shape=(32, 96), output_shape=(84, 84), detectors_shape=(6, 6), n_anchors_per_detector=8)\n",
      "  (filter_lut_2): Conv2DLUTLayer(input_shape=(84, 84), output_shape=(30, 30), detectors_shape=(6, 6), n_anchors_per_detector=8)\n",
      "  (filter_lut_3): Conv2DLUTLayer(input_shape=(30, 30), output_shape=(6, 6), detectors_shape=(6, 6), n_anchors_per_detector=8)\n",
      "  (c_luts): ModuleList(\n",
      "    (0-5): 6 x LUTLayer(36 inputs, 32 detectors, 36 outputs, 10 anchors per detector)\n",
      "  )\n",
      "  (final_lut): LUTLayer(36 inputs, 32 detectors, 100 outputs, 10 anchors per detector)\n",
      ")\n",
      "Total parameters: 92,192,762\n",
      "Trainable parameters: 92,192,762\n",
      "Number of classes: 100\n"
     ]
    }
   ],
   "source": [
    "# Create LUTNet model\n",
    "lut_net = LutNetCIFAR100(device, num_classes=len(train_dataset.classes))\n",
    "lut_net = lut_net.to(device)\n",
    "\n",
    "# Count parameters\n",
    "lut_total_params = sum(p.numel() for p in lut_net.parameters())\n",
    "lut_trainable_params = sum(p.numel() for p in lut_net.parameters() if p.requires_grad)\n",
    "\n",
    "print(f\"LUTNet Model: {lut_net}\")\n",
    "print(f\"Total parameters: {lut_total_params:,}\")\n",
    "print(f\"Trainable parameters: {lut_trainable_params:,}\")\n",
    "print(f\"Number of classes: {len(train_dataset.classes)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup optimizer and scheduler for LUTNet\n",
    "from torch.optim.lr_scheduler import LambdaLR\n",
    "\n",
    "def lr_func(t):\n",
    "    return min(\n",
    "        1.0 / (1 + t)**0.5,\n",
    "        (t / 4000.0) / 4000.0**0.5\n",
    "    )\n",
    "\n",
    "#lr=0.001\n",
    "lut_optimizer = torch.optim.SGD(\n",
    "    lut_net.parameters(),\n",
    "    lr=0.1,\n",
    "    momentum=0.9,\n",
    "    weight_decay=1e-4\n",
    ")\n",
    "#lut_optimizer = torch.optim.SGD(lut_net.parameters(), lr=0.001)\n",
    "#lut_optimizer = torch.optim.Adam(lut_net.parameters(), lr=lr)\n",
    "#lut_sched = None\n",
    "#lut_sched = LambdaLR(lut_optimizer, lr_lambda=lr_func)\n",
    "#lut_net.setup_external_learning_rate_hook(lut_optimizer)\n",
    "lut_sched = torch.optim.lr_scheduler.StepLR(\n",
    "    lut_optimizer,\n",
    "    step_size=30,\n",
    "    gamma=0.9\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training functions for LUTNet\n",
    "def train_one_epoch_lut(model, train_loader, criterion, optimizer, scheduler, device):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    pbar = tqdm(train_loader, leave=False)\n",
    "    for inputs, targets in pbar:\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "#         if scheduler is not None:\n",
    "#             for _ in range(inputs.shape[0]):\n",
    "#                 scheduler.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += targets.size(0)\n",
    "        correct += predicted.eq(targets).sum().item()\n",
    "        \n",
    "        pbar.set_description(\n",
    "            f'Loss: {loss.item():.4f}, Acc: {100.*correct/total:.2f}%, '\n",
    "            f'lr: {scheduler.get_last_lr()[0] if scheduler is not None else lr:.4f}'\n",
    "        )\n",
    "    \n",
    "    scheduler.step()\n",
    "    epoch_loss = running_loss / len(train_loader)\n",
    "    epoch_acc = 100. * correct / total\n",
    "    return epoch_loss, epoch_acc\n",
    "\n",
    "\n",
    "def evaluate_lut(model, val_loader, criterion, device):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        pbar = tqdm(val_loader, leave=False)\n",
    "        for inputs, targets in pbar:\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            \n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += targets.size(0)\n",
    "            correct += predicted.eq(targets).sum().item()\n",
    "            \n",
    "            pbar.set_description(f'Loss: {loss.item():.4f}, Acc: {100.*correct/total:.2f}%')\n",
    "    \n",
    "    epoch_loss = running_loss / len(val_loader)\n",
    "    epoch_acc = 100. * correct / total\n",
    "    return epoch_loss, epoch_acc\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LUTNet Training Loop\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LUTNet training\n",
    "lut_criterion = nn.CrossEntropyLoss()\n",
    "# def loss_func(o, t):\n",
    "#     return F.cross_entropy(\n",
    "#         o, t,\n",
    "#         reduction='none'\n",
    "#     ).sum()\n",
    "lut_train_losses = []\n",
    "lut_train_accs = []\n",
    "lut_val_losses = []\n",
    "lut_val_accs = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting LUTNet training for 100 epochs...\n",
      "Batch size: 512\n",
      "Device: cuda:5\n",
      "\n",
      "LUTNet Epoch 1/100\n",
      "Learning rate: 0.053144\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/98 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 3.0334, Train Acc: 26.09%\n",
      "Val Loss: 3.2043, Val Acc: 23.19%\n",
      "------------------------------------------------------------\n",
      "LUTNet Epoch 2/100\n",
      "Learning rate: 0.053144\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/98 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 3.0317, Train Acc: 26.05%\n",
      "Val Loss: 3.2091, Val Acc: 22.78%\n",
      "------------------------------------------------------------\n",
      "LUTNet Epoch 3/100\n",
      "Learning rate: 0.053144\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/98 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 3.0187, Train Acc: 26.09%\n",
      "Val Loss: 3.2088, Val Acc: 23.15%\n",
      "------------------------------------------------------------\n",
      "LUTNet Epoch 4/100\n",
      "Learning rate: 0.053144\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/98 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 3.0195, Train Acc: 26.18%\n",
      "Val Loss: 3.2084, Val Acc: 23.73%\n",
      "------------------------------------------------------------\n",
      "LUTNet Epoch 5/100\n",
      "Learning rate: 0.053144\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/98 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 3.0109, Train Acc: 26.42%\n",
      "Val Loss: 3.2025, Val Acc: 23.32%\n",
      "------------------------------------------------------------\n",
      "LUTNet Epoch 6/100\n",
      "Learning rate: 0.053144\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/98 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 3.0037, Train Acc: 26.51%\n",
      "Val Loss: 3.2021, Val Acc: 23.18%\n",
      "------------------------------------------------------------\n",
      "LUTNet Epoch 7/100\n",
      "Learning rate: 0.053144\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e898207b12845cd969e023dbc7d1ca2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/98 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lut_num_epochs = 100  # Adjust as needed\n",
    "\n",
    "print(f\"Starting LUTNet training for {lut_num_epochs} epochs...\")\n",
    "print(f\"Batch size: {batch_size}\")\n",
    "print(f\"Device: {device}\\n\")\n",
    "\n",
    "for epoch in range(lut_num_epochs):\n",
    "    print(f'LUTNet Epoch {epoch+1}/{lut_num_epochs}')\n",
    "    print(f'Learning rate: {lut_sched.get_last_lr()[0] if lut_sched is not None else lr:.6f}')\n",
    "    \n",
    "    # Train\n",
    "    train_loss, train_acc = train_one_epoch_lut(\n",
    "        lut_net, train_loader, lut_criterion, lut_optimizer, lut_sched, device\n",
    "    )\n",
    "    lut_train_losses.append(train_loss)\n",
    "    lut_train_accs.append(train_acc)\n",
    "    \n",
    "    # Validate\n",
    "    val_loss, val_acc = evaluate_lut(lut_net, val_loader, lut_criterion, device)\n",
    "    lut_val_losses.append(val_loss)\n",
    "    lut_val_accs.append(val_acc)\n",
    "    \n",
    "    print(f'Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.2f}%')\n",
    "    print(f'Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.2f}%')\n",
    "    print('-' * 60)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot LUTNet Results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot LUTNet training curves\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "# Loss plot\n",
    "ax1.plot(lut_train_losses, label='Train Loss', color='blue')\n",
    "ax1.plot(lut_val_losses, label='Val Loss', color='red')\n",
    "ax1.set_xlabel('Epoch')\n",
    "ax1.set_ylabel('Loss')\n",
    "ax1.set_title('LUTNet Training and Validation Loss')\n",
    "ax1.legend()\n",
    "ax1.grid(True)\n",
    "\n",
    "# Accuracy plot\n",
    "ax2.plot(lut_train_accs, label='Train Acc', color='blue')\n",
    "ax2.plot(lut_val_accs, label='Val Acc', color='red')\n",
    "ax2.set_xlabel('Epoch')\n",
    "ax2.set_ylabel('Accuracy (%)')\n",
    "ax2.set_title('LUTNet Training and Validation Accuracy')\n",
    "ax2.legend()\n",
    "ax2.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "if len(lut_val_accs) > 0:\n",
    "    print(f\"LUTNet Best validation accuracy: {max(lut_val_accs):.2f}% at epoch {lut_val_accs.index(max(lut_val_accs))+1}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_lut = Conv2DLUTLayer(\n",
    "            input_shape=(30, 30),\n",
    "            n_anchors_per_detector=8,\n",
    "            detectors_shape=(6, 6),\n",
    "            output_kernel_shape=(6, 6),\n",
    "            receptive_field_shape=(5 * 6, 5 * 6),\n",
    "            receptive_field_stride_shape=(2 * 6, 2 * 6),\n",
    "            lut_receptive_field_shape=(6, 6),\n",
    "            lut_receptive_field_stride_shape=(6, 6),\n",
    "            weights_gradient_policy=g_policy,\n",
    "            shared_context=shared_lut_ctx,\n",
    "            synapse_meta=synapse_meta,\n",
    "            summation_dtype=summation_dtype,\n",
    "            random_seed=random_seed,\n",
    "            _forward_group_size=32,\n",
    "            _backward_group_size=32,\n",
    "            _max_groups_in_growth_buffer=10**7,\n",
    "            device=device\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6, 6)"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filter_lut._output_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Conv2DLUTLayer(input_shape=(56, 56), output_shape=(20, 20), detectors_shape=(4, 4), n_anchors_per_detector=8)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filter_lut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19.0"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "76 / 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14.0"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "56 / 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "324"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "18 * 18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
