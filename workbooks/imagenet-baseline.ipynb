{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# ImageNet Baseline - Simple ResNet\n",
        "\n",
        "This notebook implements a simple baseline on ImageNet using a ResNet architecture.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Global preparations\n",
        "import sys\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader\n",
        "from tqdm.notebook import tqdm\n",
        "import numpy as np\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "random_seed = 1\n",
        "torch.manual_seed(random_seed)\n",
        "np.random.seed(random_seed)\n",
        "torch.backends.cudnn.enabled = True\n",
        "print(f\"PyTorch version: {torch.__version__}\")\n",
        "print(f\"Device: {device}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Data Loading\n",
        "\n",
        "ImageNet dataset loading with standard augmentations for training and validation.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ImageNet data paths (adjust these to your ImageNet location)\n",
        "imagenet_train_path = '/path/to/imagenet/train'  # Update this path\n",
        "imagenet_val_path = '/path/to/imagenet/val'      # Update this path\n",
        "\n",
        "# Standard ImageNet normalization\n",
        "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                                 std=[0.229, 0.224, 0.225])\n",
        "\n",
        "# Training transforms with augmentation\n",
        "train_transform = transforms.Compose([\n",
        "    transforms.RandomResizedCrop(224),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ColorJitter(brightness=0.4, contrast=0.4, saturation=0.4, hue=0.1),\n",
        "    transforms.ToTensor(),\n",
        "    normalize,\n",
        "])\n",
        "\n",
        "# Validation transforms (no augmentation)\n",
        "val_transform = transforms.Compose([\n",
        "    transforms.Resize(256),\n",
        "    transforms.CenterCrop(224),\n",
        "    transforms.ToTensor(),\n",
        "    normalize,\n",
        "])\n",
        "\n",
        "# Note: You need to have ImageNet dataset downloaded\n",
        "# For demonstration, we'll use ImageNet-like dataset or CIFAR-100 as a proxy\n",
        "# Uncomment and update paths when you have ImageNet available\n",
        "\"\"\"\n",
        "train_dataset = torchvision.datasets.ImageFolder(\n",
        "    root=imagenet_train_path,\n",
        "    transform=train_transform\n",
        ")\n",
        "\n",
        "val_dataset = torchvision.datasets.ImageFolder(\n",
        "    root=imagenet_val_path,\n",
        "    transform=val_transform\n",
        ")\n",
        "\"\"\"\n",
        "\n",
        "# Using CIFAR-100 as a smaller proxy for testing (same structure as ImageNet)\n",
        "# Replace with ImageNet when available\n",
        "print(\"Using CIFAR-100 as a proxy dataset. Replace with ImageNet for full experiments.\")\n",
        "\n",
        "train_transform_cifar = transforms.Compose([\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomCrop(32, padding=4),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5071, 0.4867, 0.4408), (0.2675, 0.2565, 0.2761)),\n",
        "])\n",
        "\n",
        "val_transform_cifar = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5071, 0.4867, 0.4408), (0.2675, 0.2565, 0.2761)),\n",
        "])\n",
        "\n",
        "train_dataset = torchvision.datasets.CIFAR100(\n",
        "    root='./data',\n",
        "    train=True,\n",
        "    download=True,\n",
        "    transform=train_transform_cifar\n",
        ")\n",
        "\n",
        "val_dataset = torchvision.datasets.CIFAR100(\n",
        "    root='./data',\n",
        "    train=False,\n",
        "    download=True,\n",
        "    transform=val_transform_cifar\n",
        ")\n",
        "\n",
        "batch_size = 128\n",
        "num_workers = 4\n",
        "\n",
        "train_loader = DataLoader(\n",
        "    train_dataset,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=True,\n",
        "    num_workers=num_workers,\n",
        "    pin_memory=True\n",
        ")\n",
        "\n",
        "val_loader = DataLoader(\n",
        "    val_dataset,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=False,\n",
        "    num_workers=num_workers,\n",
        "    pin_memory=True\n",
        ")\n",
        "\n",
        "print(f\"Train dataset size: {len(train_dataset)}\")\n",
        "print(f\"Val dataset size: {len(val_dataset)}\")\n",
        "print(f\"Number of classes: {len(train_dataset.classes)}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Baseline Model\n",
        "\n",
        "We'll use ResNet18 as a simple baseline. This can be easily replaced with ResNet50 or other architectures.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load pre-trained ResNet18 and modify for our dataset\n",
        "# For CIFAR-100, we'll modify the first conv layer to handle 32x32 images\n",
        "# For ImageNet (224x224), use standard ResNet18\n",
        "\n",
        "num_classes = len(train_dataset.classes)\n",
        "\n",
        "if hasattr(train_dataset, 'classes'):\n",
        "    # CIFAR-100 or similar small dataset\n",
        "    model = torchvision.models.resnet18(weights=None)  # Start from scratch\n",
        "    # Modify first conv layer for smaller input\n",
        "    model.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "    model.maxpool = nn.Identity()  # Remove maxpool for smaller images\n",
        "    model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
        "else:\n",
        "    # ImageNet\n",
        "    model = torchvision.models.resnet18(weights=None)\n",
        "    model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
        "\n",
        "model = model.to(device)\n",
        "\n",
        "# Count parameters\n",
        "total_params = sum(p.numel() for p in model.parameters())\n",
        "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "print(f\"Model: ResNet18\")\n",
        "print(f\"Total parameters: {total_params:,}\")\n",
        "print(f\"Trainable parameters: {trainable_params:,}\")\n",
        "print(f\"Number of classes: {num_classes}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Training Setup\n",
        "\n",
        "Define loss function, optimizer, and learning rate scheduler.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(\n",
        "    model.parameters(),\n",
        "    lr=0.1,\n",
        "    momentum=0.9,\n",
        "    weight_decay=1e-4\n",
        ")\n",
        "\n",
        "# Learning rate scheduler\n",
        "scheduler = torch.optim.lr_scheduler.StepLR(\n",
        "    optimizer,\n",
        "    step_size=30,\n",
        "    gamma=0.1\n",
        ")\n",
        "\n",
        "print(\"Optimizer: SGD with momentum 0.9, weight decay 1e-4\")\n",
        "print(\"Initial learning rate: 0.1\")\n",
        "print(\"Scheduler: StepLR (reduce by 0.1 every 30 epochs)\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Training and Evaluation Functions\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def train_one_epoch(model, train_loader, criterion, optimizer, device):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    \n",
        "    pbar = tqdm(train_loader, leave=False)\n",
        "    for inputs, targets in pbar:\n",
        "        inputs, targets = inputs.to(device), targets.to(device)\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, targets)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        running_loss += loss.item()\n",
        "        _, predicted = outputs.max(1)\n",
        "        total += targets.size(0)\n",
        "        correct += predicted.eq(targets).sum().item()\n",
        "        \n",
        "        pbar.set_description(f'Loss: {loss.item():.4f}, Acc: {100.*correct/total:.2f}%')\n",
        "    \n",
        "    epoch_loss = running_loss / len(train_loader)\n",
        "    epoch_acc = 100. * correct / total\n",
        "    return epoch_loss, epoch_acc\n",
        "\n",
        "\n",
        "def evaluate(model, val_loader, criterion, device):\n",
        "    model.eval()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        pbar = tqdm(val_loader, leave=False)\n",
        "        for inputs, targets in pbar:\n",
        "            inputs, targets = inputs.to(device), targets.to(device)\n",
        "            \n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, targets)\n",
        "            \n",
        "            running_loss += loss.item()\n",
        "            _, predicted = outputs.max(1)\n",
        "            total += targets.size(0)\n",
        "            correct += predicted.eq(targets).sum().item()\n",
        "            \n",
        "            pbar.set_description(f'Loss: {loss.item():.4f}, Acc: {100.*correct/total:.2f}%')\n",
        "    \n",
        "    epoch_loss = running_loss / len(val_loader)\n",
        "    epoch_acc = 100. * correct / total\n",
        "    return epoch_loss, epoch_acc\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Training Loop\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "num_epochs = 100  # Adjust as needed\n",
        "train_losses = []\n",
        "train_accs = []\n",
        "val_losses = []\n",
        "val_accs = []\n",
        "\n",
        "print(f\"Starting training for {num_epochs} epochs...\")\n",
        "print(f\"Batch size: {batch_size}\")\n",
        "print(f\"Device: {device}\\n\")\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    print(f'Epoch {epoch+1}/{num_epochs}')\n",
        "    print(f'Learning rate: {scheduler.get_last_lr()[0]:.6f}')\n",
        "    \n",
        "    # Train\n",
        "    train_loss, train_acc = train_one_epoch(model, train_loader, criterion, optimizer, device)\n",
        "    train_losses.append(train_loss)\n",
        "    train_accs.append(train_acc)\n",
        "    \n",
        "    # Validate\n",
        "    val_loss, val_acc = evaluate(model, val_loader, criterion, device)\n",
        "    val_losses.append(val_loss)\n",
        "    val_accs.append(val_acc)\n",
        "    \n",
        "    # Update learning rate\n",
        "    scheduler.step()\n",
        "    \n",
        "    print(f'Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.2f}%')\n",
        "    print(f'Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.2f}%')\n",
        "    print('-' * 60)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Plot Results\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Plot training curves\n",
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))\n",
        "\n",
        "# Loss plot\n",
        "ax1.plot(train_losses, label='Train Loss', color='blue')\n",
        "ax1.plot(val_losses, label='Val Loss', color='red')\n",
        "ax1.set_xlabel('Epoch')\n",
        "ax1.set_ylabel('Loss')\n",
        "ax1.set_title('Training and Validation Loss')\n",
        "ax1.legend()\n",
        "ax1.grid(True)\n",
        "\n",
        "# Accuracy plot\n",
        "ax2.plot(train_accs, label='Train Acc', color='blue')\n",
        "ax2.plot(val_accs, label='Val Acc', color='red')\n",
        "ax2.set_xlabel('Epoch')\n",
        "ax2.set_ylabel('Accuracy (%)')\n",
        "ax2.set_title('Training and Validation Accuracy')\n",
        "ax2.legend()\n",
        "ax2.grid(True)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(f\"Best validation accuracy: {max(val_accs):.2f}% at epoch {val_accs.index(max(val_accs))+1}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## LUTNet Adaptation to CIFAR-100\n",
        "\n",
        "Adapting the LUTNet architecture from MNIST to CIFAR-100 classification.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import LUTNet components\n",
        "import sys\n",
        "import os\n",
        "sys.path.insert(0, os.path.expanduser('~/spiky'))\n",
        "\n",
        "from spiky.lut.LUTLayer import (\n",
        "    LUTLayer, LUTSharedContext, SynapseMeta, GradientPolicy, GradientType\n",
        ")\n",
        "from spiky.util.torch_utils import make_lr_getter\n",
        "\n",
        "# Setup LUTNet shared context and metadata\n",
        "summation_dtype = torch.float32\n",
        "\n",
        "synapse_meta = SynapseMeta(\n",
        "    min_weight=-1.0,\n",
        "    max_weight=1.0,\n",
        "    initial_weight=0.0,\n",
        "    initial_noise_level=0.0\n",
        ")\n",
        "\n",
        "shared_lut_ctx = LUTSharedContext()\n",
        "shared_lut_ctx.to_device(device)\n",
        "g_policy = GradientPolicy(GradientType.Internal, normalized=False)\n",
        "\n",
        "print(\"LUTNet components initialized\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# LUTNet adapted for CIFAR-100\n",
        "class LutNetCIFAR100(nn.Module):\n",
        "    def __init__(self, device, num_classes=100):\n",
        "        super().__init__()\n",
        "        # CIFAR-100: 32x32x3 = 3072 inputs\n",
        "        # Use a larger first layer to handle 3-channel input\n",
        "        self.filter_lut = LUTLayer(\n",
        "            n_inputs=32 * 32 * 3,  # CIFAR-100: 32x32 RGB images\n",
        "            n_anchors_per_detector=10,\n",
        "            n_detectors=2048,\n",
        "            n_outputs=256,  # Increased from 128 for more capacity\n",
        "            synapse_meta=synapse_meta,\n",
        "            weights_gradient_policy=g_policy,\n",
        "            shared_context=shared_lut_ctx,\n",
        "            summation_dtype=summation_dtype,\n",
        "            random_seed=random_seed,\n",
        "            device=device\n",
        "        )\n",
        "        print('filter_lut finished')\n",
        "        \n",
        "        # Convolutional LUT layers with residual connections\n",
        "        l = []\n",
        "        for i in range(4):\n",
        "            l.append(\n",
        "                LUTLayer(\n",
        "                    n_inputs=256,\n",
        "                    n_anchors_per_detector=15,\n",
        "                    n_detectors=256,\n",
        "                    n_outputs=256,\n",
        "                    synapse_meta=synapse_meta,\n",
        "                    weights_gradient_policy=g_policy,\n",
        "                    shared_context=shared_lut_ctx,\n",
        "                    summation_dtype=summation_dtype,\n",
        "                    random_seed=random_seed,\n",
        "                    device=device\n",
        "                )\n",
        "            )\n",
        "            print(f'conv_lut {i} finished')\n",
        "        self.conv_luts = nn.ModuleList(l)\n",
        "        \n",
        "        # Final output layer for 100 classes\n",
        "        self.final_lut = LUTLayer(\n",
        "            n_inputs=256,\n",
        "            n_anchors_per_detector=15,\n",
        "            n_detectors=256,\n",
        "            n_outputs=num_classes,\n",
        "            synapse_meta=synapse_meta,\n",
        "            weights_gradient_policy=g_policy,\n",
        "            shared_context=shared_lut_ctx,\n",
        "            summation_dtype=summation_dtype,\n",
        "            random_seed=random_seed,\n",
        "            device=device\n",
        "        )\n",
        "        print('final_lut finished')\n",
        "\n",
        "    def forward(self, x):\n",
        "        B = x.shape[0]\n",
        "        # Flatten 32x32x3 image to 3072\n",
        "        x = x.reshape(B, 1, 32 * 32 * 3)\n",
        "        # Normalize\n",
        "        x /= (x.norm(dim=-1, keepdim=True) + 1e-16)\n",
        "        # First LUT layer\n",
        "        x = self.filter_lut(x)\n",
        "        # Residual LUT layers\n",
        "        for c_lut in self.conv_luts:\n",
        "            x = c_lut(x) + x\n",
        "        # Final output\n",
        "        return self.final_lut(x).squeeze(1)\n",
        "    \n",
        "    def setup_external_learning_rate_hook(self, optimizer):\n",
        "        lr_getter = make_lr_getter(optimizer)\n",
        "        self.filter_lut.set_external_learning_rate_hook(lr_getter)\n",
        "        for c_lut in self.conv_luts:\n",
        "            c_lut.set_external_learning_rate_hook(lr_getter)\n",
        "        self.final_lut.set_external_learning_rate_hook(lr_getter)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create LUTNet model\n",
        "lut_net = LutNetCIFAR100(device, num_classes=len(train_dataset.classes))\n",
        "lut_net = lut_net.to(device)\n",
        "\n",
        "# Count parameters\n",
        "lut_total_params = sum(p.numel() for p in lut_net.parameters())\n",
        "lut_trainable_params = sum(p.numel() for p in lut_net.parameters() if p.requires_grad)\n",
        "\n",
        "print(f\"LUTNet Model\")\n",
        "print(f\"Total parameters: {lut_total_params:,}\")\n",
        "print(f\"Trainable parameters: {lut_trainable_params:,}\")\n",
        "print(f\"Number of classes: {len(train_dataset.classes)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Setup optimizer and scheduler for LUTNet\n",
        "from torch.optim.lr_scheduler import LambdaLR\n",
        "\n",
        "def lr_func(t):\n",
        "    return min(\n",
        "        1.0 / (1 + t)**0.5,\n",
        "        (t / 4000.0) / 4000.0**0.5\n",
        "    )\n",
        "\n",
        "lut_optimizer = torch.optim.SGD(lut_net.parameters(), lr=1.0)\n",
        "lut_sched = LambdaLR(lut_optimizer, lr_lambda=lr_func)\n",
        "lut_net.setup_external_learning_rate_hook(lut_optimizer)\n",
        "\n",
        "print(\"LUTNet optimizer: SGD with lr=1.0 and LambdaLR scheduler\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Training functions for LUTNet\n",
        "def train_one_epoch_lut(model, train_loader, criterion, optimizer, scheduler, device):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    \n",
        "    pbar = tqdm(train_loader, leave=False)\n",
        "    for inputs, targets in pbar:\n",
        "        inputs, targets = inputs.to(device), targets.to(device)\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, targets)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "        \n",
        "        running_loss += loss.item()\n",
        "        _, predicted = outputs.max(1)\n",
        "        total += targets.size(0)\n",
        "        correct += predicted.eq(targets).sum().item()\n",
        "        \n",
        "        pbar.set_description(\n",
        "            f'Loss: {loss.item():.4f}, Acc: {100.*correct/total:.2f}%, '\n",
        "            f'lr: {scheduler.get_last_lr()[0]:.4f}'\n",
        "        )\n",
        "    \n",
        "    epoch_loss = running_loss / len(train_loader)\n",
        "    epoch_acc = 100. * correct / total\n",
        "    return epoch_loss, epoch_acc\n",
        "\n",
        "\n",
        "def evaluate_lut(model, val_loader, criterion, device):\n",
        "    model.eval()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        pbar = tqdm(val_loader, leave=False)\n",
        "        for inputs, targets in pbar:\n",
        "            inputs, targets = inputs.to(device), targets.to(device)\n",
        "            \n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, targets)\n",
        "            \n",
        "            running_loss += loss.item()\n",
        "            _, predicted = outputs.max(1)\n",
        "            total += targets.size(0)\n",
        "            correct += predicted.eq(targets).sum().item()\n",
        "            \n",
        "            pbar.set_description(f'Loss: {loss.item():.4f}, Acc: {100.*correct/total:.2f}%')\n",
        "    \n",
        "    epoch_loss = running_loss / len(val_loader)\n",
        "    epoch_acc = 100. * correct / total\n",
        "    return epoch_loss, epoch_acc\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## LUTNet Training Loop\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# LUTNet training\n",
        "lut_criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "lut_num_epochs = 50  # Adjust as needed\n",
        "lut_train_losses = []\n",
        "lut_train_accs = []\n",
        "lut_val_losses = []\n",
        "lut_val_accs = []\n",
        "\n",
        "print(f\"Starting LUTNet training for {lut_num_epochs} epochs...\")\n",
        "print(f\"Batch size: {batch_size}\")\n",
        "print(f\"Device: {device}\\n\")\n",
        "\n",
        "for epoch in range(lut_num_epochs):\n",
        "    print(f'LUTNet Epoch {epoch+1}/{lut_num_epochs}')\n",
        "    print(f'Learning rate: {lut_sched.get_last_lr()[0]:.6f}')\n",
        "    \n",
        "    # Train\n",
        "    train_loss, train_acc = train_one_epoch_lut(\n",
        "        lut_net, train_loader, lut_criterion, lut_optimizer, lut_sched, device\n",
        "    )\n",
        "    lut_train_losses.append(train_loss)\n",
        "    lut_train_accs.append(train_acc)\n",
        "    \n",
        "    # Validate\n",
        "    val_loss, val_acc = evaluate_lut(lut_net, val_loader, lut_criterion, device)\n",
        "    lut_val_losses.append(val_loss)\n",
        "    lut_val_accs.append(val_acc)\n",
        "    \n",
        "    print(f'Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.2f}%')\n",
        "    print(f'Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.2f}%')\n",
        "    print('-' * 60)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Plot LUTNet Results\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Plot LUTNet training curves\n",
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))\n",
        "\n",
        "# Loss plot\n",
        "ax1.plot(lut_train_losses, label='Train Loss', color='blue')\n",
        "ax1.plot(lut_val_losses, label='Val Loss', color='red')\n",
        "ax1.set_xlabel('Epoch')\n",
        "ax1.set_ylabel('Loss')\n",
        "ax1.set_title('LUTNet Training and Validation Loss')\n",
        "ax1.legend()\n",
        "ax1.grid(True)\n",
        "\n",
        "# Accuracy plot\n",
        "ax2.plot(lut_train_accs, label='Train Acc', color='blue')\n",
        "ax2.plot(lut_val_accs, label='Val Acc', color='red')\n",
        "ax2.set_xlabel('Epoch')\n",
        "ax2.set_ylabel('Accuracy (%)')\n",
        "ax2.set_title('LUTNet Training and Validation Accuracy')\n",
        "ax2.legend()\n",
        "ax2.grid(True)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "if len(lut_val_accs) > 0:\n",
        "    print(f\"LUTNet Best validation accuracy: {max(lut_val_accs):.2f}% at epoch {lut_val_accs.index(max(lut_val_accs))+1}\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
