{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Global preparations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import torch\n",
    "import torchvision\n",
    "import logging\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
    "from torchvision.transforms.functional import to_pil_image\n",
    "from PIL import Image\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "sys.path.insert(0, os.path.expanduser('~/spiky'))\n",
    "device = 'cuda:7'\n",
    "summation_dtype = torch.float32\n",
    "random_seed = 1\n",
    "torch.manual_seed(random_seed)\n",
    "np.random.seed(random_seed)\n",
    "torch.backends.cudnn.enabled = True\n",
    "logger = logging.getLogger('stdout_logger')\n",
    "logger.setLevel(logging.INFO)\n",
    "if not logger.hasHandlers():\n",
    "    stdout_handler = logging.StreamHandler(sys.stdout)\n",
    "    stdout_handler.setFormatter(logging.Formatter(fmt='%(asctime)s|%(levelname)s|%(message)s'))\n",
    "    logger.addHandler(stdout_handler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1.2+cu121\n"
     ]
    }
   ],
   "source": [
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text data preparation\n",
    "\n",
    "Let's read tinyshakespeare.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "CONTEXT_SIZE = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spiky.util.text_snippet_sampler import TextSnippetSampler\n",
    "\n",
    "snippet_sampler = TextSnippetSampler('tinyshakespeare.txt', CONTEXT_SIZE + 1, 1000, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 46,  10,  10,  76,  69,  79,  78,  84,  69,  83,  58,  10,  89, 111,\n",
       "         117,  32, 107, 110, 101, 119,  32, 111, 102,  32, 104, 105, 115,  32,\n",
       "         100, 101, 112,  97, 114, 116, 117, 114, 101,  44,  32,  97, 115,  32,\n",
       "         121, 111, 117,  32, 107, 110, 111, 119,  10,  87, 104,  97, 116,  32,\n",
       "         121, 111, 117,  32, 104,  97, 118, 101,  32, 117, 110, 100, 101, 114,\n",
       "         116,  97,  39, 101, 110,  32, 116, 111,  32, 100, 111,  32, 105, 110,\n",
       "          39, 115,  32,  97,  98, 115, 101, 110,  99, 101,  46,  10,  10,  72,\n",
       "          69,  82,  77,  73,  79,  78,  69,  58,  10,  83, 105, 114,  44,  10,\n",
       "          89, 111, 117,  32, 115, 112, 101,  97, 107,  32,  97,  32, 108,  97,\n",
       "         110, 103, 117],\n",
       "        [117,  32,  97, 114, 116,  32, 100,  97, 109, 110,  39, 100,  32, 116,\n",
       "         111,  32, 104, 101, 108, 108,  32, 102, 111, 114,  32, 116, 104, 105,\n",
       "         115,  46,  10,  10,  72,  69,  78,  82,  89,  32,  80,  69,  82,  67,\n",
       "          89,  58,  10,  65, 117, 109, 101, 114, 108, 101,  44,  32, 116, 104,\n",
       "         111, 117,  32, 108, 105, 101, 115, 116,  59,  32, 104, 105, 115,  32,\n",
       "         104, 111, 110, 111, 117, 114,  32, 105, 115,  32,  97, 115,  32, 116,\n",
       "         114, 117, 101,  10,  73, 110,  32, 116, 104, 105, 115,  32,  97, 112,\n",
       "         112, 101,  97, 108,  32,  97, 115,  32, 116, 104, 111, 117,  32,  97,\n",
       "         114, 116,  32,  97, 108, 108,  32, 117, 110, 106, 117, 115, 116,  59,\n",
       "          10,  65, 110]], device='cuda:7', dtype=torch.int32)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "snippet_sampler.sample_training_batch(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Is not this well? Come, my sweet Kate:\\nBetter once than never, for never too late.\\n\\nLUCENTIO:\\nAt last, though long, our jarring n',\n",
       " ' eyes\\nTo see alike mine honour as their profits,\\nTheir own particular thrifts, they would do that\\nWhich should undo more doing: a',\n",
       " 'd her and rid the\\nhouse of her! Come on.\\n\\nTRANIO:\\nI pray, sir, tell me, is it possible\\nThat love should of a sudden take such hol',\n",
       " ', it\\nwill also be the bondage of certain ribbons and gloves.\\n\\nMOPSA:\\nI was promised them against the feast; but they come\\nnot too']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "snippet_sampler.batch_to_text(snippet_sampler.sample_training_batch(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['range:\\nNay, it is ten times true; for truth is truth\\nTo the end of reckoning.\\n\\nDUKE VINCENTIO:\\nAway with her! Poor soul,\\nShe spea', 'd till he be three quarters\\nand a dram dead; then recovered again with\\naqua-vitae or some other hot infusion; then, raw as\\nhe is,', \"r, stay at the gate.\\n\\nJULIET:\\nNow, good sweet nurse,--O Lord, why look'st thou sad?\\nThough news be sad, yet tell them merrily;\\nIf\", \" queen,\\nWho crown'd the gracious duke in high despite,\\nLaugh'd in his face; and when with grief he wept,\\nThe ruthless queen gave \"]\n"
     ]
    }
   ],
   "source": [
    "for test_batch in snippet_sampler.testing_batches_iterator(4):\n",
    "    print(snippet_sampler.batch_to_text(test_batch))\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class ByteAutoencoder(nn.Module):\n",
    "    def __init__(self, C, d_model, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.C = C\n",
    "        self.d_model = d_model\n",
    "\n",
    "        self.embed = nn.Embedding(256, d_model)\n",
    "\n",
    "        D = C * d_model\n",
    "\n",
    "        self.enc = nn.Sequential(\n",
    "            nn.Linear(D, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "        )\n",
    "\n",
    "        self.dec = nn.Sequential(\n",
    "            nn.Linear(64, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(128, D),\n",
    "        )\n",
    "\n",
    "        self.unembed = nn.Linear(d_model, 256)\n",
    "\n",
    "    def forward(self, x):                # x: [B, C] uint8/long\n",
    "        e = self.embed(x)                # [B, C, d_model]\n",
    "        flat = e.reshape(e.size(0), -1)  # [B, C*d_model]\n",
    "\n",
    "        z = self.enc(flat)\n",
    "        rec_flat = self.dec(z)\n",
    "\n",
    "        rec = rec_flat.view(-1, self.C, self.d_model)\n",
    "        logits = self.unembed(rec)       # [B, C, 256]\n",
    "\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ae = ByteAutoencoder(CONTEXT_SIZE + 1, 128)\n",
    "ae.to(device)\n",
    "x = torch.randint(0, 256, (4, CONTEXT_SIZE + 1), dtype=torch.long, device=device)\n",
    "logits = ae(x) \n",
    "logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, sampler, B):\n",
    "    model.eval()\n",
    "    losses = []\n",
    "    device = next(model.parameters()).device\n",
    "\n",
    "    # Collect all test batches first (sampler may be a generator)\n",
    "    test_batches = list(sampler.testing_batches_iterator(B))\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in test_batches:                     # [B, C]\n",
    "            tgt = batch.long()\n",
    "\n",
    "            logits = model(batch)                      # [B, C, 256]\n",
    "\n",
    "            B_, T, V = logits.shape\n",
    "            loss = F.cross_entropy(\n",
    "                logits.reshape(B_*T, V),\n",
    "                tgt.reshape(B_*T)\n",
    "            )\n",
    "            losses.append(loss.item())\n",
    "\n",
    "    # ---- reconstruction demo ----\n",
    "    rnd_batch = test_batches[0]\n",
    "    idx = torch.randint(0, rnd_batch.size(0), (1,)).item()\n",
    "    sample = rnd_batch[idx:idx+1].to(device)           # [1, C]\n",
    "\n",
    "    with torch.no_grad():\n",
    "        logits = model(sample)\n",
    "        pred = logits.argmax(dim=-1).cpu().numpy()[0]  # [C]\n",
    "\n",
    "    orig = bytes(sample.cpu().tolist()[0])\n",
    "    recon = bytes(pred.tolist())\n",
    "\n",
    "    print(\"\\n--- Reconstruction demo ---\")\n",
    "    print(\"original:     \", orig)\n",
    "    print(\"reconstructed:\", recon)\n",
    "    print(\"----------------------------\\n\")\n",
    "\n",
    "    model.train()\n",
    "    return sum(losses) / len(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "evaluate_model(ae, snippet_sampler, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total = sum(p.numel() for p in ae.parameters())\n",
    "trainable = sum(p.numel() for p in ae.parameters() if p.requires_grad)\n",
    "\n",
    "print(\"total:\", total)\n",
    "print(\"trainable:\", trainable)\n",
    "print(\"frozen:\", total - trainable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim.lr_scheduler import LambdaLR\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import Adam, SGD\n",
    "\n",
    "lr=0.001\n",
    "#lr=0.1\n",
    "#lr=1.0\n",
    "steps=50_000\n",
    "test_every=1000\n",
    "opt = Adam([p for p in ae.parameters() if p.requires_grad], lr=lr)\n",
    "# opt = SGD([p for p in baseline_net.parameters() if p.requires_grad], lr=lr)\n",
    "def lr_func(t):\n",
    "    return min(\n",
    "        1.0 / (1 + t)**0.5,\n",
    "        (t / 4000.0) / 4000.0**0.5\n",
    "    )\n",
    "\n",
    "# sched = LambdaLR(opt, lr_lambda=lr_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_losses = []\n",
    "test_losses = []\n",
    "steps = 50_000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pbar = tqdm(total=steps)\n",
    "ae.train()\n",
    "train_loss = None\n",
    "alpha = 0.01\n",
    "\n",
    "for step in range(1, steps + 1):\n",
    "    x = snippet_sampler.sample_training_batch(batch_size)   # [B, C]\n",
    "    tgt = x.long()                                          # [B, C]\n",
    "\n",
    "    logits = ae(x)                                          # [B, C, 256]\n",
    "\n",
    "    B, T, V = logits.shape\n",
    "    loss = F.cross_entropy(\n",
    "        logits.reshape(B*T, V),\n",
    "        tgt.reshape(B*T)\n",
    "    )\n",
    "\n",
    "    opt.zero_grad()\n",
    "    loss.backward()\n",
    "    opt.step()\n",
    "\n",
    "    v = loss.item()\n",
    "    train_loss = v if train_loss is None else (1 - alpha)*train_loss + alpha*v\n",
    "\n",
    "    pbar.update(1)\n",
    "    if step % 100 == 0:\n",
    "        pbar.set_description(f\"loss={train_loss:.4f}\")\n",
    "\n",
    "    if step % test_every == 0:\n",
    "        test_loss = evaluate_model(ae, snippet_sampler, batch_size)\n",
    "        train_losses.append(train_loss)\n",
    "        test_losses.append(test_loss)\n",
    "        print(f\"[TEST] step {step}: loss={test_loss:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# assume train_losses and test_losses are Python lists of equal length\n",
    "\n",
    "steps = [i * 1000 for i in range(len(train_losses))]\n",
    "\n",
    "plt.figure(figsize=(6,4))\n",
    "plt.plot(steps, train_losses, label=\"train\")\n",
    "plt.plot(steps, test_losses, label=\"test\")\n",
    "\n",
    "plt.xlabel(\"steps\")\n",
    "plt.ylabel(\"loss\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple LUT autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from spiky.lut.LUTLayer import (\n",
    "    LUTLayer,\n",
    "    Conv2DLUTLayer,\n",
    "    LUTSharedContext,\n",
    "    GradientPolicy,\n",
    "    GradientType,\n",
    "    MultiLUT,\n",
    "    SynapseMeta\n",
    ")\n",
    "\n",
    "\n",
    "class LUTAutoencoder(nn.Module):\n",
    "    def __init__(self, C, d_model, hidden_dim, weights_gradient_policy, dropout=0.1, device=device):\n",
    "        super().__init__()\n",
    "        self.C = C\n",
    "        self.d_model = d_model\n",
    "        self.hidden_dim = hidden_dim\n",
    "\n",
    "        self.lut_shared_context = LUTSharedContext()\n",
    "        self.lut_shared_context.to_device(device)\n",
    "\n",
    "        D = C * d_model\n",
    "        \n",
    "        self.embed = nn.Embedding(256, d_model, device=device)\n",
    "        self.enc = LUTLayer(\n",
    "            n_inputs=D,\n",
    "            n_outputs=hidden_dim,\n",
    "            n_detectors=d_model * C,\n",
    "            n_anchors_per_detector=5,\n",
    "            weights_gradient_policy=weights_gradient_policy,\n",
    "            shared_context=self.lut_shared_context,\n",
    "            device=device\n",
    "        )\n",
    "\n",
    "        # ---------- Encoder ----------\n",
    "        self.hidden_layers = nn.ModuleList([\n",
    "            nn.Dropout(dropout),\n",
    "            LUTLayer(\n",
    "                n_inputs=hidden_dim,\n",
    "                n_outputs=hidden_dim,\n",
    "                n_detectors=hidden_dim * 8,\n",
    "                n_anchors_per_detector=8,\n",
    "                weights_gradient_policy=weights_gradient_policy,\n",
    "                shared_context=self.lut_shared_context,\n",
    "                device=device\n",
    "            ),\n",
    "            nn.Dropout(dropout),\n",
    "            LUTLayer(\n",
    "                n_inputs=hidden_dim,\n",
    "                n_outputs=hidden_dim,\n",
    "                n_detectors=hidden_dim * 8,\n",
    "                n_anchors_per_detector=8,\n",
    "                weights_gradient_policy=weights_gradient_policy,\n",
    "                shared_context=self.lut_shared_context,\n",
    "                device=device\n",
    "            ),\n",
    "            nn.Dropout(dropout),\n",
    "            LUTLayer(\n",
    "                n_inputs=hidden_dim,\n",
    "                n_outputs=hidden_dim,\n",
    "                n_detectors=hidden_dim * 8,\n",
    "                n_anchors_per_detector=8,\n",
    "                weights_gradient_policy=weights_gradient_policy,\n",
    "                shared_context=self.lut_shared_context,\n",
    "                device=device\n",
    "            ),\n",
    "            nn.Dropout(dropout),\n",
    "            LUTLayer(\n",
    "                n_inputs=hidden_dim,\n",
    "                n_outputs=hidden_dim,\n",
    "                n_detectors=hidden_dim * 8,\n",
    "                n_anchors_per_detector=8,\n",
    "                weights_gradient_policy=weights_gradient_policy,\n",
    "                shared_context=self.lut_shared_context,\n",
    "                device=device\n",
    "            ),\n",
    "            nn.Dropout(dropout),\n",
    "            LUTLayer(\n",
    "                n_inputs=hidden_dim,\n",
    "                n_outputs=hidden_dim,\n",
    "                n_detectors=hidden_dim * 8,\n",
    "                n_anchors_per_detector=8,\n",
    "                weights_gradient_policy=weights_gradient_policy,\n",
    "                shared_context=self.lut_shared_context,\n",
    "                device=device\n",
    "            ),\n",
    "            nn.Dropout(dropout),\n",
    "        ])\n",
    "\n",
    "        self.dec = LUTLayer(\n",
    "            n_inputs=hidden_dim,\n",
    "            n_outputs=D,\n",
    "            n_detectors=hidden_dim * 8,\n",
    "            n_anchors_per_detector=5,\n",
    "            weights_gradient_policy=weights_gradient_policy,\n",
    "            shared_context=self.lut_shared_context,\n",
    "            device=device\n",
    "        )\n",
    "\n",
    "        self.unembed = nn.Linear(d_model, 256, device=device)\n",
    "\n",
    "    # --------------------------------------------------------\n",
    "    #                NEW FORWARD (with unsqueeze/squeeze)\n",
    "    # --------------------------------------------------------\n",
    "    def forward(self, x):                # x: [B, C]\n",
    "        if self.d_model == 1:\n",
    "            e = x.to(dtype=torch.float32) / 255\n",
    "        else:\n",
    "            e = self.embed(x)                # [B, C, d_model]\n",
    "        flat = e.reshape(e.size(0), -1)  # [B, C*d_model]\n",
    "\n",
    "        h = flat.unsqueeze(1)            # <-- [B, 1, D]\n",
    "        h = self.enc(h)\n",
    "        \n",
    "        # ---------- Encoder ----------\n",
    "        for layer in self.hidden_layers:\n",
    "            h = layer(h) + h\n",
    "        \n",
    "        h = self.dec(h).squeeze(1)\n",
    "\n",
    "        rec = h.view(-1, self.C, self.d_model)  # [B, C, d_model]\n",
    "        logits = self.unembed(rec)              # [B, C, 256]\n",
    "        return logits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LUTAutoencoder(\n",
      "  (embed): Embedding(256, 1)\n",
      "  (enc): LUTLayer(129 inputs, 129 detectors, 32 outputs, 5 anchors per detector)\n",
      "  (hidden_layers): ModuleList(\n",
      "    (0): Dropout(p=0.1, inplace=False)\n",
      "    (1): LUTLayer(32 inputs, 256 detectors, 32 outputs, 8 anchors per detector)\n",
      "    (2): Dropout(p=0.1, inplace=False)\n",
      "    (3): LUTLayer(32 inputs, 256 detectors, 32 outputs, 8 anchors per detector)\n",
      "    (4): Dropout(p=0.1, inplace=False)\n",
      "    (5): LUTLayer(32 inputs, 256 detectors, 32 outputs, 8 anchors per detector)\n",
      "    (6): Dropout(p=0.1, inplace=False)\n",
      "    (7): LUTLayer(32 inputs, 256 detectors, 32 outputs, 8 anchors per detector)\n",
      "    (8): Dropout(p=0.1, inplace=False)\n",
      "    (9): LUTLayer(32 inputs, 256 detectors, 32 outputs, 8 anchors per detector)\n",
      "    (10): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (dec): LUTLayer(32 inputs, 256 detectors, 129 outputs, 5 anchors per detector)\n",
      "  (unembed): Linear(in_features=1, out_features=256, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "from spiky.lut.LUTLayer import GradientPolicy, GradientType\n",
    "lut_autoencoder = None\n",
    "optimizer = None\n",
    "sched = None\n",
    "torch.cuda.empty_cache()\n",
    "torch.cuda.ipc_collect()\n",
    "lut_autoencoder = LUTAutoencoder(\n",
    "    C=CONTEXT_SIZE+1,\n",
    "    d_model=1,\n",
    "    hidden_dim=32,\n",
    "    weights_gradient_policy=GradientPolicy(GradientType.Dense),\n",
    "    dropout=0.1,\n",
    "    device=device\n",
    ")\n",
    "print(lut_autoencoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total: 11675392\n",
      "trainable: 11675392\n",
      "frozen: 0\n"
     ]
    }
   ],
   "source": [
    "total = sum(p.numel() for p in lut_autoencoder.parameters())\n",
    "trainable = sum(p.numel() for p in lut_autoencoder.parameters() if p.requires_grad)\n",
    "\n",
    "print(\"total:\", total)\n",
    "print(\"trainable:\", trainable)\n",
    "print(\"frozen:\", total - trainable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import LambdaLR\n",
    "from spiky.util.torch_utils import make_lr_getter\n",
    "\n",
    "def lr_func(t):\n",
    "    return min(\n",
    "        1.0 / (1 + t)**0.5,\n",
    "        (t / 4000.0) / 4000.0**0.5\n",
    "    )\n",
    "\n",
    "#optimizer = optim.SGD(lut_transformer.parameters(), lr=1.0)\n",
    "#sched = LambdaLR(optimizer, lr_lambda=lr_func)\n",
    "#lut_transformer.set_external_learning_rate_hook(make_lr_getter(optimizer))\n",
    "opt = optim.Adam(lut_autoencoder.parameters(), lr=0.001)\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "lut_train_losses = []\n",
    "lut_test_losses = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b81405de94b941329288b9698909b52a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Reconstruction demo ---\n",
      "original:      b\" of Bolingbroke\\nIt is, such crimson tempest should bedrench\\nThe fresh green lap of fair King Richard's land,\\nMy stooping duty ten\"\n",
      "reconstructed: b'                                                                                                                                 '\n",
      "----------------------------\n",
      "\n",
      "[TEST] step 1000: loss=3.3024\n",
      "\n",
      "--- Reconstruction demo ---\n",
      "original:      b'\\nI have it, Tranio.\\n\\nTRANIO:\\nMaster, for my hand,\\nBoth our inventions meet and jump in one.\\n\\nLUCENTIO:\\nTell me thine first.\\n\\nTRAN'\n",
      "reconstructed: b'                                                                                                                                 '\n",
      "----------------------------\n",
      "\n",
      "[TEST] step 2000: loss=3.2519\n",
      "\n",
      "--- Reconstruction demo ---\n",
      "original:      b'd till he be three quarters\\nand a dram dead; then recovered again with\\naqua-vitae or some other hot infusion; then, raw as\\nhe is,'\n",
      "reconstructed: b'                                  \\n\\n                                                                                             '\n",
      "----------------------------\n",
      "\n",
      "[TEST] step 3000: loss=3.2252\n",
      "\n",
      "--- Reconstruction demo ---\n",
      "original:      b\"an no longer hold me patient.\\nHear me, you wrangling pirates, that fall out\\nIn sharing that which you have pill'd from me!\\nWhich \"\n",
      "reconstructed: b'                                                                                                                  \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n'\n",
      "----------------------------\n",
      "\n",
      "[TEST] step 4000: loss=3.2041\n",
      "\n",
      "--- Reconstruction demo ---\n",
      "original:      b\".\\n\\nBRUTUS:\\nDismiss them home.\\nHere comes his mother.\\n\\nSICINIUS:\\nLet's not meet her.\\n\\nBRUTUS:\\nWhy?\\n\\nSICINIUS:\\nThey say she's mad.\\n\"\n",
      "reconstructed: b'\\n\\n\\n\\n\\n\\n\\n\\n\\n                                          \\n\\n\\n\\n\\n\\n\\n\\n                                         \\n    \\n \\n                     '\n",
      "----------------------------\n",
      "\n",
      "[TEST] step 5000: loss=3.1878\n",
      "\n",
      "--- Reconstruction demo ---\n",
      "original:      b'sted gold,\\nOr stones whose rates are either rich or poor\\nAs fancy values them; but with true prayers\\nThat shall be up at heaven a'\n",
      "reconstructed: b'                                                                                                                                 '\n",
      "----------------------------\n",
      "\n",
      "[TEST] step 6000: loss=3.1773\n",
      "\n",
      "--- Reconstruction demo ---\n",
      "original:      b'range:\\nNay, it is ten times true; for truth is truth\\nTo the end of reckoning.\\n\\nDUKE VINCENTIO:\\nAway with her! Poor soul,\\nShe spea'\n",
      "reconstructed: b'                                                                               \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n                                   '\n",
      "----------------------------\n",
      "\n",
      "[TEST] step 7000: loss=3.1707\n",
      "\n",
      "--- Reconstruction demo ---\n",
      "original:      b\" grace not being warn'd thereof before:\\nMy lord, he fears you mean no good to him.\\n\\nBUCKINGHAM:\\nSorry I am my noble cousin should\"\n",
      "reconstructed: b'                                                                                \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n                                 '\n",
      "----------------------------\n",
      "\n",
      "[TEST] step 8000: loss=3.1664\n",
      "\n",
      "--- Reconstruction demo ---\n",
      "original:      b'then but innocence shall make\\nFalse accusation blush and tyranny\\nTremble at patience. You, my lord, best know,\\nWho least will see'\n",
      "reconstructed: b'                        \\n \\n\\n                                                                                                     '\n",
      "----------------------------\n",
      "\n",
      "[TEST] step 9000: loss=3.1626\n",
      "\n",
      "--- Reconstruction demo ---\n",
      "original:      b'thee with old cramps,\\nFill all thy bones with aches, make thee roar\\nThat beasts shall tremble at thy din.\\n\\nCALIBAN:\\nNo, pray thee'\n",
      "reconstructed: b'                                                                                                      \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n            '\n",
      "----------------------------\n",
      "\n",
      "[TEST] step 10000: loss=3.1612\n",
      "\n",
      "--- Reconstruction demo ---\n",
      "original:      b\"\\nThat's yet unbruised: bring me but out at gate.\\nCome, my sweet wife, my dearest mother, and\\nMy friends of noble touch, when I am\"\n",
      "reconstructed: b'                                                                                                                                 '\n",
      "----------------------------\n",
      "\n",
      "[TEST] step 11000: loss=3.1575\n",
      "\n",
      "--- Reconstruction demo ---\n",
      "original:      b\"an no longer hold me patient.\\nHear me, you wrangling pirates, that fall out\\nIn sharing that which you have pill'd from me!\\nWhich \"\n",
      "reconstructed: b'                                                                                                                          \\n\\n     '\n",
      "----------------------------\n",
      "\n",
      "[TEST] step 12000: loss=3.1569\n",
      "\n",
      "--- Reconstruction demo ---\n",
      "original:      b're prepare yourself to\\ndeath: do not satisfy your resolution with hopes\\nthat are fallible: tomorrow you must die; go to\\nyour knee'\n",
      "reconstructed: b'                                                                                                                                 '\n",
      "----------------------------\n",
      "\n",
      "[TEST] step 13000: loss=3.1541\n",
      "\n",
      "--- Reconstruction demo ---\n",
      "original:      b'range:\\nNay, it is ten times true; for truth is truth\\nTo the end of reckoning.\\n\\nDUKE VINCENTIO:\\nAway with her! Poor soul,\\nShe spea'\n",
      "reconstructed: b'                                                                            \\n\\n\\n\\n\\n\\nE\\n\\nEE\\n\\n\\n\\n\\n\\n                                    '\n",
      "----------------------------\n",
      "\n",
      "[TEST] step 14000: loss=3.1514\n",
      "\n",
      "--- Reconstruction demo ---\n",
      "original:      b\"\\nThat's yet unbruised: bring me but out at gate.\\nCome, my sweet wife, my dearest mother, and\\nMy friends of noble touch, when I am\"\n",
      "reconstructed: b'                                                                                                                                 '\n",
      "----------------------------\n",
      "\n",
      "[TEST] step 15000: loss=3.1516\n",
      "\n",
      "--- Reconstruction demo ---\n",
      "original:      b'two courses off to\\nsea again; lay her off.\\n\\nMariners:\\nAll lost! to prayers, to prayers! all lost!\\n\\nBoatswain:\\nWhat, must our mout'\n",
      "reconstructed: b'                                  \\n\\n                                                  \\n\\n                                         '\n",
      "----------------------------\n",
      "\n",
      "[TEST] step 16000: loss=3.1508\n",
      "\n",
      "--- Reconstruction demo ---\n",
      "original:      b\"\\nThat's yet unbruised: bring me but out at gate.\\nCome, my sweet wife, my dearest mother, and\\nMy friends of noble touch, when I am\"\n",
      "reconstructed: b'                                                                                                                                 '\n",
      "----------------------------\n",
      "\n",
      "[TEST] step 17000: loss=3.1472\n",
      "\n",
      "--- Reconstruction demo ---\n",
      "original:      b\" of Bolingbroke\\nIt is, such crimson tempest should bedrench\\nThe fresh green lap of fair King Richard's land,\\nMy stooping duty ten\"\n",
      "reconstructed: b'                                                                                                      \\n\\n\\n \\n\\n                     '\n",
      "----------------------------\n",
      "\n",
      "[TEST] step 18000: loss=3.1467\n",
      "\n",
      "--- Reconstruction demo ---\n",
      "original:      b'withal.\\n\\nTRANIO:\\nAnd here I take the unfeigned oath,\\nNever to marry with her though she would entreat:\\nFie on her! see, how beast'\n",
      "reconstructed: b'          \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n                                                                                                            '\n",
      "----------------------------\n",
      "\n",
      "[TEST] step 19000: loss=3.1474\n",
      "\n",
      "--- Reconstruction demo ---\n",
      "original:      b\"et aboard;\\nLook to thy bark: I'll not be long before\\nI call upon thee.\\n\\nMariner:\\nMake your best haste, and go not\\nToo far i' the \"\n",
      "reconstructed: b'                                                                                                                                 '\n",
      "----------------------------\n",
      "\n",
      "[TEST] step 20000: loss=3.1463\n",
      "\n",
      "--- Reconstruction demo ---\n",
      "original:      b\".\\n\\nBRUTUS:\\nDismiss them home.\\nHere comes his mother.\\n\\nSICINIUS:\\nLet's not meet her.\\n\\nBRUTUS:\\nWhy?\\n\\nSICINIUS:\\nThey say she's mad.\\n\"\n",
      "reconstructed: b'\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n                             tt          \\n\\n\\n             t                               \\n\\n\\n\\n                       '\n",
      "----------------------------\n",
      "\n",
      "[TEST] step 21000: loss=3.1444\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Reconstruction demo ---\n",
      "original:      b\".\\n\\nBRUTUS:\\nDismiss them home.\\nHere comes his mother.\\n\\nSICINIUS:\\nLet's not meet her.\\n\\nBRUTUS:\\nWhy?\\n\\nSICINIUS:\\nThey say she's mad.\\n\"\n",
      "reconstructed: b'\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n                                            \\n\\n\\n                                        \\n\\n \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n                   '\n",
      "----------------------------\n",
      "\n",
      "[TEST] step 22000: loss=3.1438\n",
      "\n",
      "--- Reconstruction demo ---\n",
      "original:      b\"sing of blood-sucking sighs,\\nLest with my sighs or tears I blast or drown\\nKing Edward's fruit, true heir to the English crown.\\n\\nR\"\n",
      "reconstructed: b'                                                                                                                      \\n\\n\\n        '\n",
      "----------------------------\n",
      "\n",
      "[TEST] step 23000: loss=3.1430\n",
      "\n",
      "--- Reconstruction demo ---\n",
      "original:      b\"re Isabel! should it then be thus?\\nNo; I would tell what 'twere to be a judge,\\nAnd what a prisoner.\\n\\nLUCIO:\\n\\nANGELO:\\nYour brother\"\n",
      "reconstructed: b'                                                                        \\n\\n\\n\\n\\n                        \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n                 '\n",
      "----------------------------\n",
      "\n",
      "[TEST] step 24000: loss=3.1412\n",
      "\n",
      "--- Reconstruction demo ---\n",
      "original:      b\"et aboard;\\nLook to thy bark: I'll not be long before\\nI call upon thee.\\n\\nMariner:\\nMake your best haste, and go not\\nToo far i' the \"\n",
      "reconstructed: b'                                                                                      t                                          '\n",
      "----------------------------\n",
      "\n",
      "[TEST] step 25000: loss=3.1395\n",
      "\n",
      "--- Reconstruction demo ---\n",
      "original:      b'thee with old cramps,\\nFill all thy bones with aches, make thee roar\\nThat beasts shall tremble at thy din.\\n\\nCALIBAN:\\nNo, pray thee'\n",
      "reconstructed: b'                                                                                                         \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n            '\n",
      "----------------------------\n",
      "\n",
      "[TEST] step 26000: loss=3.1402\n",
      "\n",
      "--- Reconstruction demo ---\n",
      "original:      b\" have you slept, my lord?\\n\\nRICHMOND:\\nThe sweetest sleep, and fairest-boding dreams\\nThat ever enter'd in a drowsy head,\\nHave I sin\"\n",
      "reconstructed: b'                       \\n\\n\\n\\nEEEEEEE\\n\\n\\n\\n    tt                                                                                \\n\\n   '\n",
      "----------------------------\n",
      "\n",
      "[TEST] step 27000: loss=3.1397\n",
      "\n",
      "--- Reconstruction demo ---\n",
      "original:      b\"ose and to put it\\nIn execution.\\n\\nBRUTUS:\\n'Tis most like he will.\\n\\nSICINIUS:\\nIt shall be to him then as our good wills,\\nA sure des\"\n",
      "reconstructed: b'                                                               \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n                                                     '\n",
      "----------------------------\n",
      "\n",
      "[TEST] step 28000: loss=3.1381\n",
      "\n",
      "--- Reconstruction demo ---\n",
      "original:      b'thee with old cramps,\\nFill all thy bones with aches, make thee roar\\nThat beasts shall tremble at thy din.\\n\\nCALIBAN:\\nNo, pray thee'\n",
      "reconstructed: b'                                                                                                         \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n         '\n",
      "----------------------------\n",
      "\n",
      "[TEST] step 29000: loss=3.1382\n",
      "\n",
      "--- Reconstruction demo ---\n",
      "original:      b\" have you slept, my lord?\\n\\nRICHMOND:\\nThe sweetest sleep, and fairest-boding dreams\\nThat ever enter'd in a drowsy head,\\nHave I sin\"\n",
      "reconstructed: b'                      \\n\\n\\n\\n\\n\\nEEEEEE\\n\\n\\n                                                                                            '\n",
      "----------------------------\n",
      "\n",
      "[TEST] step 30000: loss=3.1372\n",
      "\n",
      "--- Reconstruction demo ---\n",
      "original:      b'ceed the father but the son?\\n\\nRICHARD:\\nAre you there, butcher? O, I cannot speak!\\n\\nCLIFFORD:\\nAy, crook-back, here I stand to answ'\n",
      "reconstructed: b'                        \\n\\n\\n\\n\\nEEEE\\n\\n\\n\\n\\n                          \\n               \\n\\n\\nEEEEE\\n\\n\\n\\n\\n\\n                                   '\n",
      "----------------------------\n",
      "\n",
      "[TEST] step 31000: loss=3.1371\n",
      "\n",
      "--- Reconstruction demo ---\n",
      "original:      b\"r, stay at the gate.\\n\\nJULIET:\\nNow, good sweet nurse,--O Lord, why look'st thou sad?\\nThough news be sad, yet tell them merrily;\\nIf\"\n",
      "reconstructed: b'                                                                                                                                 '\n",
      "----------------------------\n",
      "\n",
      "[TEST] step 32000: loss=3.1347\n",
      "\n",
      "--- Reconstruction demo ---\n",
      "original:      b're prepare yourself to\\ndeath: do not satisfy your resolution with hopes\\nthat are fallible: tomorrow you must die; go to\\nyour knee'\n",
      "reconstructed: b'                            \\n                                                                                                    '\n",
      "----------------------------\n",
      "\n",
      "[TEST] step 33000: loss=3.1335\n",
      "\n",
      "--- Reconstruction demo ---\n",
      "original:      b\"an no longer hold me patient.\\nHear me, you wrangling pirates, that fall out\\nIn sharing that which you have pill'd from me!\\nWhich \"\n",
      "reconstructed: b'                                                                                                                         \\n\\n\\n\\n\\n\\n\\n\\n'\n",
      "----------------------------\n",
      "\n",
      "[TEST] step 34000: loss=3.1332\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[58], line 21\u001b[0m\n\u001b[1;32m     15\u001b[0m loss \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mcross_entropy(\n\u001b[1;32m     16\u001b[0m     logits\u001b[38;5;241m.\u001b[39mreshape(B\u001b[38;5;241m*\u001b[39mT, V),\n\u001b[1;32m     17\u001b[0m     tgt\u001b[38;5;241m.\u001b[39mreshape(B\u001b[38;5;241m*\u001b[39mT)\n\u001b[1;32m     18\u001b[0m )\n\u001b[1;32m     20\u001b[0m opt\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m---> 21\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     22\u001b[0m opt\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     24\u001b[0m v \u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n",
      "File \u001b[0;32m~/vr_venv/lib/python3.8/site-packages/torch/_tensor.py:492\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    482\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    483\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    484\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    485\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    490\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    491\u001b[0m     )\n\u001b[0;32m--> 492\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    493\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    494\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/vr_venv/lib/python3.8/site-packages/torch/autograd/__init__.py:251\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    246\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    248\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    250\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 251\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    252\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    256\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    257\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    258\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    259\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "steps=50000\n",
    "test_every=1000\n",
    "train_loss = None\n",
    "alpha = 0.01\n",
    "pbar = tqdm(total=steps)\n",
    "lut_autoencoder.train()\n",
    "\n",
    "for step in range(1, steps + 1):\n",
    "    x = snippet_sampler.sample_training_batch(batch_size)   # [B, C]\n",
    "    tgt = x.long()                                          # [B, C]\n",
    "\n",
    "    logits = lut_autoencoder(x)                                          # [B, C, 256]\n",
    "\n",
    "    B, T, V = logits.shape\n",
    "    loss = F.cross_entropy(\n",
    "        logits.reshape(B*T, V),\n",
    "        tgt.reshape(B*T)\n",
    "    )\n",
    "\n",
    "    opt.zero_grad()\n",
    "    loss.backward()\n",
    "    opt.step()\n",
    "\n",
    "    v = loss.item()\n",
    "    train_loss = v if train_loss is None else (1 - alpha)*train_loss + alpha*v\n",
    "\n",
    "    pbar.update(1)\n",
    "    if step % 100 == 0:\n",
    "        pbar.set_description(f\"loss={train_loss:.4f}\")\n",
    "\n",
    "    if step % test_every == 0:\n",
    "        test_loss = evaluate_model(lut_autoencoder, snippet_sampler, batch_size)\n",
    "        lut_train_losses.append(train_loss)\n",
    "        lut_test_losses.append(test_loss)\n",
    "        print(f\"[TEST] step {step}: loss={test_loss:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# assume train_losses and test_losses are Python lists of equal length\n",
    "\n",
    "steps = [i * 1000 for i in range(len(lut_train_losses))]\n",
    "\n",
    "plt.figure(figsize=(6,4))\n",
    "plt.plot(steps, lut_train_losses, label=\"train\")\n",
    "plt.plot(steps, lut_test_losses, label=\"test\")\n",
    "\n",
    "plt.xlabel(\"steps\")\n",
    "plt.ylabel(\"loss\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# assume train_losses and test_losses are Python lists of equal length\n",
    "\n",
    "steps = [i * 1000 for i in range(len(lut_train_losses))]\n",
    "\n",
    "plt.figure(figsize=(6,4))\n",
    "plt.plot(steps, lut_train_losses, label=\"train\")\n",
    "plt.plot(steps, lut_test_losses, label=\"test\")\n",
    "\n",
    "plt.xlabel(\"steps\")\n",
    "plt.ylabel(\"loss\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# assume train_losses and test_losses are Python lists of equal length\n",
    "\n",
    "steps = [i * 1000 for i in range(len(lut_train_losses))]\n",
    "\n",
    "plt.figure(figsize=(6,4))\n",
    "plt.plot(steps, lut_train_losses, label=\"train\")\n",
    "plt.plot(steps, lut_test_losses, label=\"test\")\n",
    "\n",
    "plt.xlabel(\"steps\")\n",
    "plt.ylabel(\"loss\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_text_lut(lut_transformer, 'Once upon a time: ', length=80, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(lut_transformer.get_profile_statistics())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_model(lut_transformer, snippet_sampler, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = torch.rand([16, 1 << (6 + 6 + 4), 32])\n",
    "w.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp = torch.rand([128, 1024, 32])\n",
    "inp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "after_d = torch.rand([128, 1024, 16, 65536], device=device)\n",
    "after_d.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
